# LLM Provider Configuration
LLM_PROVIDER=gemini
LLM_API_KEY=AIzaSyAvAF28-EnMYV_jBY22opCtgwXudBsnYmY
LLM_MODEL=gemini-2.5-flash
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=8192

# Uncomment and fill these to use OpenAI instead
# LLM_PROVIDER=openai
# LLM_API_KEY=your-openai-api-key-here
# LLM_MODEL=gpt-4o
# LLM_API_URL=https://api.openai.com/v1  # Optional custom endpoint

# Application settings
PORT=8000
DEBUG=true